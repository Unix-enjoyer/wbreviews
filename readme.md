Программа по переносу данных из большого файла json в posgresql с использованием docker. Для запуска выполнить: 
0) активировать окружение venv 
1) pip install -r requirements.txt
1)  docker-compose up -d для запуска docker и находящегося в нем postgres, остановка docker-compose down, Просмотр логов docker-compose logs -f postgres
2)  python test_connnection.py для проверки работоспособности
3)  python loader.py для начала чтения "по кускам" исходного файла
4)  для просмотра изменений использовать dbeaver, взяв значения из файла config и установив подключение к бд

в корне проекта должны лежать обрабатываемые данные
одна бд, несколько таблиц
в файле конфиг меняются только обрабатываемые данные и настройки батчей
get-pip  скачивал через curl, в проклятом питоне новых версий его нет
docker file при добавлении 2 таблицы не меняется, тк контейнер тот же. Меняется database.py где указываем вторую таблицу

для второго датасета есть сохранение контрольных точек. ctrl-c останвавливает выполнение обработки, подождать, пока сохранит контрольную точку. Потом можно перезапустить контейнер. не допускать аварийного завершения, чтобы были контрольные точки. при приближении к переполнению памяти программа делает контрольную точку.

датасет 1
мой датасет, отзывы на товары

датасет 2
датасет М.В, список товаров

nmID - артикул на вб - join по нему
item name - имя товара


imt_id = идентификатор товара (item ID)
nm_id = номенклатурный ID
imt_name = название товара (item name)